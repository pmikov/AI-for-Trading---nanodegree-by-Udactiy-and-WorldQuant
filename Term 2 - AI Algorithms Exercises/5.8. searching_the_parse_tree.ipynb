{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching The Parse Tree\n",
    "\n",
    "BeautifulSoup provides a number of methods for searching the parse tree, but we will only cover the `.find_all()` method in this lesson. You can learn about other search methods in the [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).\n",
    "\n",
    "The `.find_all(filter)` method will search an entire document for the given `filter`. The `filter` can be a string containing the HTML or XML tag name, a tag attribute, or even a regular expression. In this notebook we will see examples of these cases. \n",
    "\n",
    "So let's begin by using the `.find_all()` method to find all `<h2>` tags in our `sample.html` file. To do this, we will pass the string `'h2'` to the `.find_all()` method as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"h2style\" id=\"hub\">Student Hub</h2>, <h2 class=\"h2style\" id=\"know\">Knowledge</h2>]\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Find all the h2 tags\n",
    "h2_list = page_content.find_all('h2')\n",
    "\n",
    "# Print the h2_list\n",
    "print(h2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `.find_all()` method returns a list with all the `<h2>` tags. Since lists are iterables, we can loop through the `h2_list` to print each tag, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 class=\"h2style\" id=\"hub\">Student Hub</h2>\n",
      "<h2 class=\"h2style\" id=\"know\">Knowledge</h2>\n"
     ]
    }
   ],
   "source": [
    "# Print each tag in the h2_list\n",
    "for tag in h2_list:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Find All The `<p>` Tags\n",
    "\n",
    "In the cell below, use the `.find_all()` method to find all the `<p>` tags in the `sample.html` file. Start by opening the `sample.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then use the `.find_all()` method to find all the `<p>` tags from the `page_content` object. Save the list returned by the `.find_all()` method in a variable called `p_list`. Finally, loop through the list and print each tag in the list. Since the `<p>` tags contain subtags, use the `.prettify()` method to improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>\n",
      " Student Hub is our real time collaboration platform where you can work with peers and mentors. You will find Community rooms with other students and alumni.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Search or ask questions in\n",
      " <a href=\"https://knowledge.udacity.com/\">\n",
      "  Knowledge\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Good luck and we hope you enjoy the course\n",
      "</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Find all the p tags\n",
    "p_list = page_content.find_all('p')\n",
    "\n",
    "# Print each tag in the p_list\n",
    "for tag in p_list:\n",
    "    print(tag.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching For Multiple Tags\n",
    "\n",
    "We can also search for more than one tag at a time by passing a list to the `.find_all()` method. Let's see an example.\n",
    "\n",
    "Let's suppose we wanted to search for all the `<h2>` and `<p>` tags in our `sample.html` file. Instead of using two statements (one for each tag):\n",
    "\n",
    "```python\n",
    "h2_list = page_content.find_all('h2')\n",
    "p_list = page_content.find_all('p')\n",
    "```\n",
    "\n",
    "we can just pass the list `['h2', 'p']` to the `.find_all()` method, as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 class=\"h2style\" id=\"hub\">\n",
      " Student Hub\n",
      "</h2>\n",
      "\n",
      "<p>\n",
      " Student Hub is our real time collaboration platform where you can work with peers and mentors. You will find Community rooms with other students and alumni.\n",
      "</p>\n",
      "\n",
      "<h2 class=\"h2style\" id=\"know\">\n",
      " Knowledge\n",
      "</h2>\n",
      "\n",
      "<p>\n",
      " Search or ask questions in\n",
      " <a href=\"https://knowledge.udacity.com/\">\n",
      "  Knowledge\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Good luck and we hope you enjoy the course\n",
      "</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "# Print all the h2 and p tags\n",
    "for tag in page_content.find_all(['h2', 'p']):\n",
    "    print(tag.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get all the `<h2>` and `<p>` tags in our file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Find All The `<a>` and `<link>` Tags\n",
    "\n",
    "In the cell below, use the `.find_all()` method to find all the `<a>` and `<link>` tags in the `sample.html` file. Start by opening the `sample.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then find all the `<a>` and`<link>` tags from the `page_content` object by passing a list to the `.find_all()` method. Loop through the list and print each tag in the list. Use the `.prettify()` method to improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<link href=\"./teststyle.css\" rel=\"stylesheet\"/>\n",
      "\n",
      "<a href=\"https://knowledge.udacity.com/\">\n",
      " Knowledge\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "# Print all the a and link tags\n",
    "for tag in page_content.find_all(['a', 'link']):\n",
    "    print(tag.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching For Tags With Particular Attributes\n",
    "\n",
    "The `.find_all()` method also allows us to pass some arguments, such as the attribute of a tag, so that we can search the entire document for the exact tag we want. For example, in our `sample.html` file, we have two `<h2>` tags:\n",
    "\n",
    "1. `<h2 class=\"h2style\" id=\"hub\">Student Hub</h2>`\n",
    "\n",
    "2. `<h2 class=\"h2style\" id=\"know\">Knowledge</h2>`\n",
    "\n",
    "We can see that the first `<h2>` tag has the attribute `id=\"hub\"`, while the second `<h2>` tag has the attribute `id=\"know\"`. Let's suppose, we only wanted to search our `sample.html` document for the `<h2>` tag that had `id=\"know\"`. To do this, we will add the `id` attribute to the `.find_all()` method as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 class=\"h2style\" id=\"know\">Knowledge</h2>\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Find the h2 tag with id = know\n",
    "h2_know = page_content.find_all('h2', id = 'know')\n",
    "\n",
    "# Print each item in the h2_know\n",
    "for tag in h2_know:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, the list returned by the `.find_all()` method only has one element, and it corresponds to the `<h2>` tag that has `id=\"know\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Find All The `<h1>` Tags With The Attribute `id='intro'`\n",
    "\n",
    "In the cell below, use the `.find_all()` method to find all the `<h1>` tags in the `sample.html` file that have the attribute `id=\"intro\"`. Start by opening the `sample.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then find all the `<h1>` tags that have the attribute `id=\"intro\"` from the `page_content` object. Loop through the list and print each tag in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"intro\">Get Help From Peers and Mentors</h1>\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Print all the h1 tags with id = intro\n",
    "for tag in page_content.find_all('h1', id = 'intro'):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching For Attributes Directly\n",
    "\n",
    "The `.find_all()` method also allows us to search for tag attributes directly. For example, we can search for all the tags that have the attribute `id=\"intro\"` by only passing this attribute to the `.find_all()` method, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"intro\">Get Help From Peers and Mentors</h1>\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Print all the tags with id = intro\n",
    "for tag in page_content.find_all(id = 'intro'):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we only get one tag, since the `<h1>` tag is the only tag in our document that has the attribute `id=\"intro\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Find All Tags With Attribute `id='hub'`\n",
    "\n",
    "In the cell below, use the `.find_all()` method to find all the tags in the `sample.html` file that have the attribute `id=\"hub\"`. Start by opening the `sample.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then find all the tags that have the attribute `id=\"hub\"` from the `page_content` object. Loop through the list and print each tag in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 class=\"h2style\" id=\"hub\">Student Hub</h2>\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Print all the tags with id = hub\n",
    "for tag in page_content.find_all(id = 'hub'):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching by `class`\n",
    "\n",
    "Let's suppose we wanted to find all the tags that had the attribute `class=\"h2style\"`. Unfortunately, in this case, we can't simply pass this attribute to the `.find_all()` method. The reason is that the **CSS** attribute, `class`, is a reserved word in Python. Therefore, using `class` as a keyword argument in the `.find_all()` method, will give you a syntax error. To get around this problem, BeautifulSoup has implemented the keyword `class_` (notice the underscore at the end) that can be used to search for the `class` attribute. Let's see how this works.\n",
    "\n",
    "In the code below, we will use the `.find_all()` method to search for all the tags in our `sample.html` file that have the attribute `class=\"h2style\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "# Print the tags that have the attribute class_ = 'h2style'\n",
    "for tag in page_content.find_all(class_ = 'h2style'):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get the two `<h2>` tags since they are the only ones in our document that have the attribute class=\"h2style\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching With Regular Expressions\n",
    "\n",
    "We can also pass a regular expression object to the `.find_all()` method. Let's see an example. The code below uses a regular expression to find all the tags whose names contain the letter `i`. Remember that in order to use regular expressions we must import the `re` module. In this particular example we will be only interested in printing the tag name and not its entire content. In order to do this, we will use the `.name` attribute of the `Tag` object to only print the name of tag itself, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import the re module\n",
    "import re \n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "# Print only the tag names of all the tags whose name contain the letter i\n",
    "for tag in page_content.find_all(re.compile(r'i')):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Find All Tags The Start With The Letter `h`\n",
    "\n",
    "In the cell below, pass a regular expression to the `.find_all()` method to find all the tags whose names start with the letter `h`. Start by opening the `sample.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then find all the tags whose names start with the letter `h` by passing a regular expression to the `.find_all()` method. Loop through the list and print each tag in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import the re module\n",
    "import re \n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "# Print only the tag names of all the tags whose names start with the letter h\n",
    "for tag in page_content.find_all(re.compile(r'^h')):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag's Children\n",
    "\n",
    "We saw in an earlier lesson that tags may contain other tags and strings within in them. These elements are known as the tag’s children. For simplicity, in the following examples we will use a simpler HTML file named `sample2.html`. So let's print it to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and print the head tag\n",
    "with open('./sample2.html') as f:\n",
    "    print(BeautifulSoup(f, 'lxml').prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `<html>` tag contains some child tags. For example, the `<head>` tag is a direct child of the `<html>` tag. Similarly, the `<title>` tag is a direct child of the `<head>` tag. We also see that the `<title>` tag itself has a child, namely the string `'AI For Trading'`. BeautifulSoup provides a lot of different attributes for navigating over a tag’s children. We already saw that we can access child tags as if they were attributes of the parent tag. For example, we can access the string `'AI For Trading'` from our `soup` object by using:\n",
    "\n",
    "```python\n",
    "soup.head.title.get_text()\n",
    "```\n",
    "as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and print the text in the title tag within the head tag\n",
    "with open('./sample2.html') as f:\n",
    "    print(BeautifulSoup(f, 'lxml').head.title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view a tag's children by using the `.contents` attribute of the Tag object. The `.contents` attribute returns a list with all the tag's children. By counting the number of elements in this list we can see how many children a parent tag has. In the code below we print the children of the `<head>` tag and we also print the number children the `<head>` tag has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample2.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Access the head tag\n",
    "page_head = page_content.head\n",
    "\n",
    "# Print the children of the head tag\n",
    "print(page_head.contents)\n",
    "\n",
    "# Print the number of children of the head tag\n",
    "print('\\nThe <head> tag contains {} children'.format(len(page_head.contents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Get The Children from the `<title>`  Tag\n",
    "\n",
    "In the cell below, print the contents and the number of children of the `<title>` tag in the `sample2.html` file. Start by opening the `sample2.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then access the `<title>` tag and save the tag object in variable called `page_title`. Then use the `.contents` attribute to print the contents and the number of children of the `<title>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample2.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Access the title tag\n",
    "page_title = page_content.head.title\n",
    "\n",
    "# Print the children of the title tag\n",
    "print(page_title.contents)\n",
    "\n",
    "# Print the number of children of the title tag\n",
    "print('\\nThe <title> contains {} children'.format(len(page_title.contents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note, that strings do not have children because they can’t contain anything. \n",
    "\n",
    "Instead of getting a tag's children as a list, we can also get an iterator that we loop over by using the `.children` attribute. In the code below we create a loop to iterate over the `<head>` tag's children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample2.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Print the children of the head tag\n",
    "for child in page_content.head.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Loop Through The Children The `<title>`  Tag\n",
    "\n",
    "In the cell below, print the children of the `<title>` tag in the `sample2.html` file. Start by opening the `sample2.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then create a loop that prints the children of the `<title>` tag using the `.children` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample2.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Print the children of the head tag\n",
    "for child in page_content.head.title.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Recursive Argument\n",
    "\n",
    "If we use the `.find_all()` method on a Tag object, `tag.find_all()`,then the `find_all()` method will search all the tag's children, its children’s children, and so on. However, there will be times where you only want BeautifulSoup to search a tag's direct children. To do this, we can pass the `recursive=False` argument, to the `.find_all()` method. Let's see an example.\n",
    "\n",
    "Let's start by printing our `sample2.html` file again to see what its structure looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and print the head tag\n",
    "with open('./sample2.html') as f:\n",
    "    print(BeautifulSoup(f, 'lxml').prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `<head>` tag is directly beneath the `<html>` tag and that the `<title>` tag is directly beneath the `<head>` tag. Even though the `<title>` tag is beneath the `<html>` tag, it’s **not** directly beneath it, because the `<head>` tag is in between them. \n",
    "\n",
    "Now, if we search the `<html>` tag for the `<title>` tag, using the `.find_all()` method, BeautifulSoup will find it because it is searching in all of the descendants of the `<html>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample2.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "# Search the html tag for the title tag\n",
    "for tag in page_content.html.find_all('title'):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the we get a match.\n",
    "\n",
    "Now, let's restrict our search to only look at the `<html>` tag’s direct children, by using the `recursive=False` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample2.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Search the html tag's direct children for the title tag\n",
    "for tag in page_content.html.find_all('title', recursive = False):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now we don't get any matches because the `<title>` tag is **not** a direct descendent of the `<html>` tag.\n",
    "\n",
    "# TODO: Search For The `<head>` Tag\n",
    "\n",
    "In the cell below, search for the `<head>` tag only in the direct children of the `<html>` tag in the `sample2.html` file. Start by opening the `sample2.html` file and passing the open filehandle to the BeautifulSoup constructor using the `lxml` parser. Save the BeautifulSoup object returned by the constructor in a variable called `page_content`. Then search the html tag's direct children for the `<head>` tag  using the `recursive=False` argument. Print the result using the `.prettify()` attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample2.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "# Search the html tag's direct children for the head tag    \n",
    "for tag in page_content.html.find_all('head', recursive = False):\n",
    "    print(tag.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Exercise: Get Headers and Paragraphs\n",
    "\n",
    "In the cell below, use what you learned in the previous lessons to print only the text from all the `<h2>` and `<p>` tags inside the `<div>` tags that have a `class=\"section\"` attribute. For this quiz use the `sampe.html` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the HTML file and create a BeautifulSoup Object\n",
    "with open('./sample.html') as f:\n",
    "    page_content = BeautifulSoup(f, 'lxml')\n",
    "\n",
    "# Print only the text from all the <h2> and <p> tags inside the <div> tags that have a class=\"section\" attribute\n",
    "for section in page_content.find_all('div', class_='section'):\n",
    "    header = section.h2.get_text()\n",
    "    print(header)\n",
    "    paragraph = section.p.get_text()\n",
    "    print(paragraph)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
